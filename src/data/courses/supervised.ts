import { TeachingStep } from '../../types';

export const supervisedSteps: TeachingStep[] = [
    {
        id: 'sl-1',
        stepNumber: 1,
        title: 'Introduction to Supervised Learning',
        content: 'Supervised learning uses labeled training data to learn a mapping from inputs to outputs. The algorithm learns from examples where both the input and correct output are provided.',
        spokenContent: 'Welcome to Supervised Learning! This is the most common form of machine learning. Think of it as learning with a teacher. We give the computer a massive "labeled" dataset—thousands of examples of inputs and their correct answers. The algorithm then finds the patterns that connect the two, so it can predict answers for data it has never seen before.',
        visualType: 'technical',
        visualPrompt: 'High-tech data pipeline showing "Raw Data" and "Labels" merging into a training model node with accuracy readouts',
        durationSeconds: 160,
        completed: false,
        complexity: 'basic',
        estimatedMinutes: 3,
        keyConcepts: ['Labeled Data', 'Mapping Function', 'Training Set', 'Ground Truth'],
        realWorldExamples: [
            'Email filters learning what "spam" looks like',
            'Image apps identifying your face in photos',
            'Predicting house prices based on previous sales'
        ],
    },
    {
        id: 'sl-2',
        stepNumber: 2,
        title: 'Classification vs Regression',
        content: 'Classification predicts discrete categories (like spam/not spam). Regression predicts continuous values (like house prices). Both use labeled training data but have different output types.',
        spokenContent: 'Supervised learning generally does two things. Classification is about categories — is this a cat or a dog? Regression is about continuous numbers — what will the price of gold be tomorrow? Whether it\'s a label or a number, we use previous examples to forecast the future.',
        visualType: 'technical',
        visualPrompt: 'Dual-pane visualization showing a decision boundary separating dots (Classification) versus a line-of-best-fit through data points (Regression)',
        durationSeconds: 180,
        completed: false,
        complexity: 'basic',
        estimatedMinutes: 3,
        keyConcepts: ['Discrete Classes', 'Continuous Values', 'Output Space', 'Supervised Tasks'],
    },
    {
        id: 'sl-3',
        stepNumber: 3,
        title: 'The Training Process',
        content: 'The algorithm processes training examples, calculates error (loss), and adjusts its parameters to minimize that error. This repeats through multiple epochs until it learns the pattern.',
        spokenContent: 'How does the learning actually happen? It’s an iterative loop. The model makes a guess, calculates how far off it was—this is the "Loss"—and then slightly tweaks its internal settings to be a bit more accurate next time. After thousands or millions of these tiny adjustments, the model converges on the right pattern.',
        visualType: 'animation',
        visualPrompt: 'Moving graph showing a loss curve dropping towards zero as the model\'s internal weights pulse and adjust in real-time',
        durationSeconds: 200,
        completed: false,
        complexity: 'intermediate',
        estimatedMinutes: 4,
        keyConcepts: ['Loss Function', 'Optimization', 'Epochs', 'Model Weights'],
    },
    {
        id: 'sl-4',
        stepNumber: 4,
        title: 'Linear Regression & Trees',
        content: 'Popular algorithms include Linear Regression for trends and Decision Trees for logical rules. Neural Networks are more complex models inspired by the brain\'s structure.',
        spokenContent: 'We have different "architectures" for learning. Linear Regression fits a straight line to data trends. Decision Trees are like a giant flow chart of if-then questions. And Neural Networks go even deeper, with layers of mathematical "neurons" that can learn incredibly complex patterns, like human speech or medical diagnoses.',
        visualType: 'technical',
        visualPrompt: 'Split-view showing a Decision Tree branching logic and a multi-layer Neural Network with active firing nodes',
        durationSeconds: 200,
        completed: false,
        complexity: 'intermediate',
        estimatedMinutes: 4,
        keyConcepts: ['Linear Models', 'Decision Logic', 'Hidden Layers', 'Neurons'],
    },
    {
        id: 'sl-5',
        stepNumber: 5,
        title: 'ML Mastery Check',
        content: 'Evaluate model performance and recognize when a model is "Overfitting" the training data.',
        spokenContent: 'You are now an ML apprentice! The final challenge is knowing when your model is actually learning or just memorizing the test. We call it "Overfitting" when a model is too smart for its own good. Let’s see if you can spot the signs of a model that has stopped learning patterns and started just memorizing data.',
        visualType: 'animation',
        visualPrompt: 'Knowledge check dashboard with interactive performance curves showing training vs validation divergence',
        durationSeconds: 150,
        completed: false,
        complexity: 'advanced',
        estimatedMinutes: 3,
    },
];
